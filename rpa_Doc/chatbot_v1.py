import json
import os
import sys
import pickle
import subprocess

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ---------------- CONFIG ----------------
DOC_FILE = "output/month_document_contents_filtered.json"
EMBED_FILE = "output/tfidf_embeddings.pkl"
TOP_K = 2
OLLAMA_MODEL = "llama3.2:1b"   # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (ollama pull llama3)
# ----------------------------------------

def load_documents():
    if not os.path.exists(DOC_FILE):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {DOC_FILE}")
        sys.exit(1)

    with open(DOC_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    chunks = []
    for month in data:
        for doc in month.get("documents", []):
            text = (
                f"‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠: {doc.get('‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠','')}\n"
                f"‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á: {doc.get('‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á','')}\n"
                f"‡∏Ç‡πâ‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢: {doc.get('‡∏Ç‡πâ‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢','')}\n"
                f"‡∏Ç‡πâ‡∏≠‡∏´‡∏≤‡∏£‡∏∑‡∏≠: {doc.get('‡∏Ç‡πâ‡∏≠‡∏´‡∏≤‡∏£‡∏∑‡∏≠','')}\n"
                f"‡πÅ‡∏ô‡∏ß‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢: {doc.get('‡πÅ‡∏ô‡∏ß‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢','')}"
            )
            chunks.append(text)

    print(f"üìå ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(chunks)} chunks")
    return chunks

def load_or_create_embeddings(chunks):
    if os.path.exists(EMBED_FILE):
        with open(EMBED_FILE, "rb") as f:
            vectorizer, X = pickle.load(f)
        print("üìå ‡πÇ‡∏´‡∏•‡∏î embeddings ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß")
    else:
        vectorizer = TfidfVectorizer()
        X = vectorizer.fit_transform(chunks)

        os.makedirs(os.path.dirname(EMBED_FILE), exist_ok=True)
        with open(EMBED_FILE, "wb") as f:
            pickle.dump((vectorizer, X), f)

        print("üìå ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

    return vectorizer, X

def search_chunks(question, vectorizer, X, chunks, k=TOP_K):
    q_vec = vectorizer.transform([question])
    scores = cosine_similarity(q_vec, X)[0]
    top_ids = scores.argsort()[::-1][:k]
    
    results = []
    for i in top_ids:
        results.append({
            "text": chunks[i],
            "score": scores[i]
        })
    return results

def ask_ollama(prompt):
    print("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 10‚Äì30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)...")

    try:
        result = subprocess.run(
            ["ollama", "run", OLLAMA_MODEL],
            input=prompt,
            capture_output=True,
            text=True,
            encoding="utf-8",
            timeout=60   # ‚è±Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        )

        if result.returncode != 0:
            print("‚ùå Ollama error:")
            print(result.stderr)
            return None

        return result.stdout.strip()

    except subprocess.TimeoutExpired:
        print("‚ùå Ollama ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")
        return None

def main():
    chunks = load_documents()
    vectorizer, X = load_or_create_embeddings(chunks)

    print("üéâ ChatBot ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô! ‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å")

    while True:
        question = input("\n‡∏ñ‡∏≤‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£: ").strip()
        if question.lower() == "exit":
            break
        if not question:
            continue

        search_results = search_chunks(question, vectorizer, X, chunks)
        
        context_text = ""
        print("\nüîç ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î:")
        for i, res in enumerate(search_results):
            score_pct = res['score'] * 100
            # ‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå‡πÉ‡∏ô Terminal ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™
            book_id = "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
            for line in res['text'].split('\n'):
                if "‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠:" in line:
                    book_id = line.replace("‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠:", "").strip()
            
            print(f" {i+1}. [{book_id}] - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {score_pct:.2f}%")
            context_text += f"--- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà {i+1} ---\n{res['text']}\n\n"

        prompt = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£\n"
            "‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n"
            "‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠' ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n\n"
            "========== ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ==========\n"
            + context_text
            + "========== ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ==========\n"
            + question
            + "\n\n========== ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ==========\n"
        )

        answer = ask_ollama(prompt)
        if answer:
            print("\nü§ñ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI:")
            print("-" * 30)
            print(answer)
            print("-" * 30)
        else:
            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI ‡πÑ‡∏î‡πâ")

if __name__ == "__main__":
    main()
