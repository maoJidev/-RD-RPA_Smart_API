import json
import os
import sys
import pickle
import subprocess

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ---------------- CONFIG ----------------
DOC_FILE = "output/month_document_contents_filtered.json"
EMBED_FILE = "output/tfidf_embeddings.pkl"
TOP_K = 2
OLLAMA_MODEL = "llama3.2:1b"
# ----------------------------------------


# ---------------- UTILS ----------------
def clear_screen():
    os.system("cls" if os.name == "nt" else "clear")


def print_header():
    print("=" * 60)
    print("ü§ñ ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£ (RAG + Ollama)")
    print("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ChatGPT")
    print("‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏û‡∏¥‡πÄ‡∏®‡∏©: /help  /clear  /exit")
    print("=" * 60)


def read_multiline_input(prompt="You: "):
    """
    ‡∏£‡∏±‡∏ö input ‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
    ‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á
    """
    print(prompt, end="", flush=True)
    lines = []
    while True:
        line = input()
        if line.strip() == "":
            break
        lines.append(line)
    return "\n".join(lines).strip()


# ---------------- LOAD DATA ----------------
def load_documents():
    if not os.path.exists(DOC_FILE):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {DOC_FILE}")
        sys.exit(1)

    with open(DOC_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    chunks = []
    for month in data:
        for doc in month.get("documents", []):
            text = (
                f"‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠: {doc.get('‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠','')}\n"
                f"‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á: {doc.get('‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á','')}\n"
                f"‡∏Ç‡πâ‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢: {doc.get('‡∏Ç‡πâ‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢','')}\n"
                f"‡∏Ç‡πâ‡∏≠‡∏´‡∏≤‡∏£‡∏∑‡∏≠: {doc.get('‡∏Ç‡πâ‡∏≠‡∏´‡∏≤‡∏£‡∏∑‡∏≠','')}\n"
                f"‡πÅ‡∏ô‡∏ß‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢: {doc.get('‡πÅ‡∏ô‡∏ß‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢','')}"
            )
            chunks.append(text)

    print(f"üìå ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(chunks)} ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á")
    return chunks


def load_or_create_embeddings(chunks):
    if os.path.exists(EMBED_FILE):
        with open(EMBED_FILE, "rb") as f:
            vectorizer, X = pickle.load(f)
        print("üìå ‡πÇ‡∏´‡∏•‡∏î embeddings ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
    else:
        vectorizer = TfidfVectorizer()
        X = vectorizer.fit_transform(chunks)

        os.makedirs(os.path.dirname(EMBED_FILE), exist_ok=True)
        with open(EMBED_FILE, "wb") as f:
            pickle.dump((vectorizer, X), f)

        print("üìå ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

    return vectorizer, X


# ---------------- SEARCH ----------------
def search_chunks(question, vectorizer, X, chunks, k=TOP_K):
    q_vec = vectorizer.transform([question])
    scores = cosine_similarity(q_vec, X)[0]
    top_ids = scores.argsort()[::-1][:k]

    results = []
    for i in top_ids:
        results.append({
            "text": chunks[i],
            "score": scores[i]
        })
    return results


# ---------------- OLLAMA ----------------
def ask_ollama(prompt):
    print("\nü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...\n")

    try:
        result = subprocess.run(
            ["ollama", "run", OLLAMA_MODEL],
            input=prompt,
            capture_output=True,
            text=True,
            encoding="utf-8",
            timeout=60
        )

        if result.returncode != 0:
            print("‚ùå Ollama error:")
            print(result.stderr)
            return None

        return result.stdout.strip()

    except subprocess.TimeoutExpired:
        print("‚ùå Ollama ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")
        return None


# ---------------- MAIN CHAT LOOP ----------------
def main():
    clear_screen()
    print_header()

    chunks = load_documents()
    vectorizer, X = load_or_create_embeddings(chunks)

    while True:
        question = read_multiline_input("\nYou:\n")

        if not question:
            continue

        if question.lower() in ["/exit", "exit", "quit"]:
            print("\nüëã ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö")
            break

        if question.lower() == "/clear":
            clear_screen()
            print_header()
            continue

        if question.lower() == "/help":
            print("\nüìñ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            print("- ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î")
            print("- ‡∏Å‡∏î Enter ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
            print("- /clear ‡∏•‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠")
            print("- /exit ‡∏≠‡∏≠‡∏Å")
            continue

        # --------- SEARCH ---------
        search_results = search_chunks(question, vectorizer, X, chunks)

        print("\nüîç ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:")
        context_text = ""

        for i, res in enumerate(search_results):
            score_pct = res["score"] * 100
            book_id = "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"

            for line in res["text"].split("\n"):
                if "‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠:" in line:
                    book_id = line.replace("‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠:", "").strip()

            print(f" {i+1}. {book_id} ({score_pct:.2f}%)")
            context_text += f"--- ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà {i+1} ---\n{res['text']}\n\n"

        # --------- PROMPT ---------
        prompt = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£\n"
            "‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n"
            "‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ '‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠' ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n\n"
            "========== ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ==========\n"
            + context_text +
            "========== ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ==========\n"
            + question +
            "\n\n========== ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ==========\n"
        )

        answer = ask_ollama(prompt)

        if answer:
            print("\nAI:")
            print("-" * 60)
            print(answer)
            print("-" * 60)
        else:
            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ")


if __name__ == "__main__":
    main()
